{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[EXAMPLE] RL Example Agents for Nbr Guessing with TF Agents.ipynb","provenance":[{"file_id":"1bseg9DTI5Fc_XD-wnacQbXoqKGqtJ73i","timestamp":1609763871949}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Gu4f8NsjMjdI"},"source":["# Examples of Agents in a Number Guessing Environment\n","\n","Contributors: michaelmenzel@google.com"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HvTRcRf3b1ja","cellView":"form","executionInfo":{"status":"ok","timestamp":1609340816653,"user_tz":-60,"elapsed":9732,"user":{"displayName":"Michael Menzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghb_AthsQBGiw6bqarv0qCUUv4_xqG97Nchzmvqjck=s64","userId":"08013474203105065423"}},"outputId":"41541ab3-5c7a-452f-f76b-1adadc040bd7"},"source":["#@title Imports\n","!pip3 install --upgrade --quiet gym tf-agents\n","\n","import numpy as np\n","\n","import gym\n","from gym import envs\n","from gym import spaces\n","from gym.utils import seeding\n","\n","import tensorflow as tf\n","\n","from tf_agents.networks import q_network, q_rnn_network, actor_distribution_network, value_network\n","from tf_agents.agents.dqn import dqn_agent\n","from tf_agents.agents import PPOAgent\n","from tf_agents.environments import suite_gym\n","from tf_agents.environments import tf_py_environment\n","from tf_agents.replay_buffers import tf_uniform_replay_buffer\n","from tf_agents.drivers import dynamic_step_driver\n","from tf_agents.metrics.tf_metrics import AverageEpisodeLengthMetric, AverageReturnMetric, ChosenActionHistogram, NumberOfEpisodes\n","from tf_agents.utils import common"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.6MB 23.8MB/s \n","\u001b[K     |████████████████████████████████| 1.1MB 47.2MB/s \n","\u001b[?25h  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"cellView":"form","id":"x-gwdhv-eu1Y","executionInfo":{"status":"ok","timestamp":1609340816654,"user_tz":-60,"elapsed":5287,"user":{"displayName":"Michael Menzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghb_AthsQBGiw6bqarv0qCUUv4_xqG97Nchzmvqjck=s64","userId":"08013474203105065423"}},"outputId":"191b028f-3391-4cc8-d4af-584739ab1b70"},"source":["#@title Available Gym Environments\n","', '.join(map(lambda e: e.id, envs.registry.all()))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Copy-v0, RepeatCopy-v0, ReversedAddition-v0, ReversedAddition3-v0, DuplicatedInput-v0, Reverse-v0, CartPole-v0, CartPole-v1, MountainCar-v0, MountainCarContinuous-v0, Pendulum-v0, Acrobot-v1, LunarLander-v2, LunarLanderContinuous-v2, BipedalWalker-v3, BipedalWalkerHardcore-v3, CarRacing-v0, Blackjack-v0, KellyCoinflip-v0, KellyCoinflipGeneralized-v0, FrozenLake-v0, FrozenLake8x8-v0, CliffWalking-v0, NChain-v0, Roulette-v0, Taxi-v3, GuessingGame-v0, HotterColder-v0, Reacher-v2, Pusher-v2, Thrower-v2, Striker-v2, InvertedPendulum-v2, InvertedDoublePendulum-v2, HalfCheetah-v2, HalfCheetah-v3, Hopper-v2, Hopper-v3, Swimmer-v2, Swimmer-v3, Walker2d-v2, Walker2d-v3, Ant-v2, Ant-v3, Humanoid-v2, Humanoid-v3, HumanoidStandup-v2, FetchSlide-v1, FetchPickAndPlace-v1, FetchReach-v1, FetchPush-v1, HandReach-v0, HandManipulateBlockRotateZ-v0, HandManipulateBlockRotateZTouchSensors-v0, HandManipulateBlockRotateZTouchSensors-v1, HandManipulateBlockRotateParallel-v0, HandManipulateBlockRotateParallelTouchSensors-v0, HandManipulateBlockRotateParallelTouchSensors-v1, HandManipulateBlockRotateXYZ-v0, HandManipulateBlockRotateXYZTouchSensors-v0, HandManipulateBlockRotateXYZTouchSensors-v1, HandManipulateBlockFull-v0, HandManipulateBlock-v0, HandManipulateBlockTouchSensors-v0, HandManipulateBlockTouchSensors-v1, HandManipulateEggRotate-v0, HandManipulateEggRotateTouchSensors-v0, HandManipulateEggRotateTouchSensors-v1, HandManipulateEggFull-v0, HandManipulateEgg-v0, HandManipulateEggTouchSensors-v0, HandManipulateEggTouchSensors-v1, HandManipulatePenRotate-v0, HandManipulatePenRotateTouchSensors-v0, HandManipulatePenRotateTouchSensors-v1, HandManipulatePenFull-v0, HandManipulatePen-v0, HandManipulatePenTouchSensors-v0, HandManipulatePenTouchSensors-v1, FetchSlideDense-v1, FetchPickAndPlaceDense-v1, FetchReachDense-v1, FetchPushDense-v1, HandReachDense-v0, HandManipulateBlockRotateZDense-v0, HandManipulateBlockRotateZTouchSensorsDense-v0, HandManipulateBlockRotateZTouchSensorsDense-v1, HandManipulateBlockRotateParallelDense-v0, HandManipulateBlockRotateParallelTouchSensorsDense-v0, HandManipulateBlockRotateParallelTouchSensorsDense-v1, HandManipulateBlockRotateXYZDense-v0, HandManipulateBlockRotateXYZTouchSensorsDense-v0, HandManipulateBlockRotateXYZTouchSensorsDense-v1, HandManipulateBlockFullDense-v0, HandManipulateBlockDense-v0, HandManipulateBlockTouchSensorsDense-v0, HandManipulateBlockTouchSensorsDense-v1, HandManipulateEggRotateDense-v0, HandManipulateEggRotateTouchSensorsDense-v0, HandManipulateEggRotateTouchSensorsDense-v1, HandManipulateEggFullDense-v0, HandManipulateEggDense-v0, HandManipulateEggTouchSensorsDense-v0, HandManipulateEggTouchSensorsDense-v1, HandManipulatePenRotateDense-v0, HandManipulatePenRotateTouchSensorsDense-v0, HandManipulatePenRotateTouchSensorsDense-v1, HandManipulatePenFullDense-v0, HandManipulatePenDense-v0, HandManipulatePenTouchSensorsDense-v0, HandManipulatePenTouchSensorsDense-v1, Adventure-v0, Adventure-v4, AdventureDeterministic-v0, AdventureDeterministic-v4, AdventureNoFrameskip-v0, AdventureNoFrameskip-v4, Adventure-ram-v0, Adventure-ram-v4, Adventure-ramDeterministic-v0, Adventure-ramDeterministic-v4, Adventure-ramNoFrameskip-v0, Adventure-ramNoFrameskip-v4, AirRaid-v0, AirRaid-v4, AirRaidDeterministic-v0, AirRaidDeterministic-v4, AirRaidNoFrameskip-v0, AirRaidNoFrameskip-v4, AirRaid-ram-v0, AirRaid-ram-v4, AirRaid-ramDeterministic-v0, AirRaid-ramDeterministic-v4, AirRaid-ramNoFrameskip-v0, AirRaid-ramNoFrameskip-v4, Alien-v0, Alien-v4, AlienDeterministic-v0, AlienDeterministic-v4, AlienNoFrameskip-v0, AlienNoFrameskip-v4, Alien-ram-v0, Alien-ram-v4, Alien-ramDeterministic-v0, Alien-ramDeterministic-v4, Alien-ramNoFrameskip-v0, Alien-ramNoFrameskip-v4, Amidar-v0, Amidar-v4, AmidarDeterministic-v0, AmidarDeterministic-v4, AmidarNoFrameskip-v0, AmidarNoFrameskip-v4, Amidar-ram-v0, Amidar-ram-v4, Amidar-ramDeterministic-v0, Amidar-ramDeterministic-v4, Amidar-ramNoFrameskip-v0, Amidar-ramNoFrameskip-v4, Assault-v0, Assault-v4, AssaultDeterministic-v0, AssaultDeterministic-v4, AssaultNoFrameskip-v0, AssaultNoFrameskip-v4, Assault-ram-v0, Assault-ram-v4, Assault-ramDeterministic-v0, Assault-ramDeterministic-v4, Assault-ramNoFrameskip-v0, Assault-ramNoFrameskip-v4, Asterix-v0, Asterix-v4, AsterixDeterministic-v0, AsterixDeterministic-v4, AsterixNoFrameskip-v0, AsterixNoFrameskip-v4, Asterix-ram-v0, Asterix-ram-v4, Asterix-ramDeterministic-v0, Asterix-ramDeterministic-v4, Asterix-ramNoFrameskip-v0, Asterix-ramNoFrameskip-v4, Asteroids-v0, Asteroids-v4, AsteroidsDeterministic-v0, AsteroidsDeterministic-v4, AsteroidsNoFrameskip-v0, AsteroidsNoFrameskip-v4, Asteroids-ram-v0, Asteroids-ram-v4, Asteroids-ramDeterministic-v0, Asteroids-ramDeterministic-v4, Asteroids-ramNoFrameskip-v0, Asteroids-ramNoFrameskip-v4, Atlantis-v0, Atlantis-v4, AtlantisDeterministic-v0, AtlantisDeterministic-v4, AtlantisNoFrameskip-v0, AtlantisNoFrameskip-v4, Atlantis-ram-v0, Atlantis-ram-v4, Atlantis-ramDeterministic-v0, Atlantis-ramDeterministic-v4, Atlantis-ramNoFrameskip-v0, Atlantis-ramNoFrameskip-v4, BankHeist-v0, BankHeist-v4, BankHeistDeterministic-v0, BankHeistDeterministic-v4, BankHeistNoFrameskip-v0, BankHeistNoFrameskip-v4, BankHeist-ram-v0, BankHeist-ram-v4, BankHeist-ramDeterministic-v0, BankHeist-ramDeterministic-v4, BankHeist-ramNoFrameskip-v0, BankHeist-ramNoFrameskip-v4, BattleZone-v0, BattleZone-v4, BattleZoneDeterministic-v0, BattleZoneDeterministic-v4, BattleZoneNoFrameskip-v0, BattleZoneNoFrameskip-v4, BattleZone-ram-v0, BattleZone-ram-v4, BattleZone-ramDeterministic-v0, BattleZone-ramDeterministic-v4, BattleZone-ramNoFrameskip-v0, BattleZone-ramNoFrameskip-v4, BeamRider-v0, BeamRider-v4, BeamRiderDeterministic-v0, BeamRiderDeterministic-v4, BeamRiderNoFrameskip-v0, BeamRiderNoFrameskip-v4, BeamRider-ram-v0, BeamRider-ram-v4, BeamRider-ramDeterministic-v0, BeamRider-ramDeterministic-v4, BeamRider-ramNoFrameskip-v0, BeamRider-ramNoFrameskip-v4, Berzerk-v0, Berzerk-v4, BerzerkDeterministic-v0, BerzerkDeterministic-v4, BerzerkNoFrameskip-v0, BerzerkNoFrameskip-v4, Berzerk-ram-v0, Berzerk-ram-v4, Berzerk-ramDeterministic-v0, Berzerk-ramDeterministic-v4, Berzerk-ramNoFrameskip-v0, Berzerk-ramNoFrameskip-v4, Bowling-v0, Bowling-v4, BowlingDeterministic-v0, BowlingDeterministic-v4, BowlingNoFrameskip-v0, BowlingNoFrameskip-v4, Bowling-ram-v0, Bowling-ram-v4, Bowling-ramDeterministic-v0, Bowling-ramDeterministic-v4, Bowling-ramNoFrameskip-v0, Bowling-ramNoFrameskip-v4, Boxing-v0, Boxing-v4, BoxingDeterministic-v0, BoxingDeterministic-v4, BoxingNoFrameskip-v0, BoxingNoFrameskip-v4, Boxing-ram-v0, Boxing-ram-v4, Boxing-ramDeterministic-v0, Boxing-ramDeterministic-v4, Boxing-ramNoFrameskip-v0, Boxing-ramNoFrameskip-v4, Breakout-v0, Breakout-v4, BreakoutDeterministic-v0, BreakoutDeterministic-v4, BreakoutNoFrameskip-v0, BreakoutNoFrameskip-v4, Breakout-ram-v0, Breakout-ram-v4, Breakout-ramDeterministic-v0, Breakout-ramDeterministic-v4, Breakout-ramNoFrameskip-v0, Breakout-ramNoFrameskip-v4, Carnival-v0, Carnival-v4, CarnivalDeterministic-v0, CarnivalDeterministic-v4, CarnivalNoFrameskip-v0, CarnivalNoFrameskip-v4, Carnival-ram-v0, Carnival-ram-v4, Carnival-ramDeterministic-v0, Carnival-ramDeterministic-v4, Carnival-ramNoFrameskip-v0, Carnival-ramNoFrameskip-v4, Centipede-v0, Centipede-v4, CentipedeDeterministic-v0, CentipedeDeterministic-v4, CentipedeNoFrameskip-v0, CentipedeNoFrameskip-v4, Centipede-ram-v0, Centipede-ram-v4, Centipede-ramDeterministic-v0, Centipede-ramDeterministic-v4, Centipede-ramNoFrameskip-v0, Centipede-ramNoFrameskip-v4, ChopperCommand-v0, ChopperCommand-v4, ChopperCommandDeterministic-v0, ChopperCommandDeterministic-v4, ChopperCommandNoFrameskip-v0, ChopperCommandNoFrameskip-v4, ChopperCommand-ram-v0, ChopperCommand-ram-v4, ChopperCommand-ramDeterministic-v0, ChopperCommand-ramDeterministic-v4, ChopperCommand-ramNoFrameskip-v0, ChopperCommand-ramNoFrameskip-v4, CrazyClimber-v0, CrazyClimber-v4, CrazyClimberDeterministic-v0, CrazyClimberDeterministic-v4, CrazyClimberNoFrameskip-v0, CrazyClimberNoFrameskip-v4, CrazyClimber-ram-v0, CrazyClimber-ram-v4, CrazyClimber-ramDeterministic-v0, CrazyClimber-ramDeterministic-v4, CrazyClimber-ramNoFrameskip-v0, CrazyClimber-ramNoFrameskip-v4, Defender-v0, Defender-v4, DefenderDeterministic-v0, DefenderDeterministic-v4, DefenderNoFrameskip-v0, DefenderNoFrameskip-v4, Defender-ram-v0, Defender-ram-v4, Defender-ramDeterministic-v0, Defender-ramDeterministic-v4, Defender-ramNoFrameskip-v0, Defender-ramNoFrameskip-v4, DemonAttack-v0, DemonAttack-v4, DemonAttackDeterministic-v0, DemonAttackDeterministic-v4, DemonAttackNoFrameskip-v0, DemonAttackNoFrameskip-v4, DemonAttack-ram-v0, DemonAttack-ram-v4, DemonAttack-ramDeterministic-v0, DemonAttack-ramDeterministic-v4, DemonAttack-ramNoFrameskip-v0, DemonAttack-ramNoFrameskip-v4, DoubleDunk-v0, DoubleDunk-v4, DoubleDunkDeterministic-v0, DoubleDunkDeterministic-v4, DoubleDunkNoFrameskip-v0, DoubleDunkNoFrameskip-v4, DoubleDunk-ram-v0, DoubleDunk-ram-v4, DoubleDunk-ramDeterministic-v0, DoubleDunk-ramDeterministic-v4, DoubleDunk-ramNoFrameskip-v0, DoubleDunk-ramNoFrameskip-v4, ElevatorAction-v0, ElevatorAction-v4, ElevatorActionDeterministic-v0, ElevatorActionDeterministic-v4, ElevatorActionNoFrameskip-v0, ElevatorActionNoFrameskip-v4, ElevatorAction-ram-v0, ElevatorAction-ram-v4, ElevatorAction-ramDeterministic-v0, ElevatorAction-ramDeterministic-v4, ElevatorAction-ramNoFrameskip-v0, ElevatorAction-ramNoFrameskip-v4, Enduro-v0, Enduro-v4, EnduroDeterministic-v0, EnduroDeterministic-v4, EnduroNoFrameskip-v0, EnduroNoFrameskip-v4, Enduro-ram-v0, Enduro-ram-v4, Enduro-ramDeterministic-v0, Enduro-ramDeterministic-v4, Enduro-ramNoFrameskip-v0, Enduro-ramNoFrameskip-v4, FishingDerby-v0, FishingDerby-v4, FishingDerbyDeterministic-v0, FishingDerbyDeterministic-v4, FishingDerbyNoFrameskip-v0, FishingDerbyNoFrameskip-v4, FishingDerby-ram-v0, FishingDerby-ram-v4, FishingDerby-ramDeterministic-v0, FishingDerby-ramDeterministic-v4, FishingDerby-ramNoFrameskip-v0, FishingDerby-ramNoFrameskip-v4, Freeway-v0, Freeway-v4, FreewayDeterministic-v0, FreewayDeterministic-v4, FreewayNoFrameskip-v0, FreewayNoFrameskip-v4, Freeway-ram-v0, Freeway-ram-v4, Freeway-ramDeterministic-v0, Freeway-ramDeterministic-v4, Freeway-ramNoFrameskip-v0, Freeway-ramNoFrameskip-v4, Frostbite-v0, Frostbite-v4, FrostbiteDeterministic-v0, FrostbiteDeterministic-v4, FrostbiteNoFrameskip-v0, FrostbiteNoFrameskip-v4, Frostbite-ram-v0, Frostbite-ram-v4, Frostbite-ramDeterministic-v0, Frostbite-ramDeterministic-v4, Frostbite-ramNoFrameskip-v0, Frostbite-ramNoFrameskip-v4, Gopher-v0, Gopher-v4, GopherDeterministic-v0, GopherDeterministic-v4, GopherNoFrameskip-v0, GopherNoFrameskip-v4, Gopher-ram-v0, Gopher-ram-v4, Gopher-ramDeterministic-v0, Gopher-ramDeterministic-v4, Gopher-ramNoFrameskip-v0, Gopher-ramNoFrameskip-v4, Gravitar-v0, Gravitar-v4, GravitarDeterministic-v0, GravitarDeterministic-v4, GravitarNoFrameskip-v0, GravitarNoFrameskip-v4, Gravitar-ram-v0, Gravitar-ram-v4, Gravitar-ramDeterministic-v0, Gravitar-ramDeterministic-v4, Gravitar-ramNoFrameskip-v0, Gravitar-ramNoFrameskip-v4, Hero-v0, Hero-v4, HeroDeterministic-v0, HeroDeterministic-v4, HeroNoFrameskip-v0, HeroNoFrameskip-v4, Hero-ram-v0, Hero-ram-v4, Hero-ramDeterministic-v0, Hero-ramDeterministic-v4, Hero-ramNoFrameskip-v0, Hero-ramNoFrameskip-v4, IceHockey-v0, IceHockey-v4, IceHockeyDeterministic-v0, IceHockeyDeterministic-v4, IceHockeyNoFrameskip-v0, IceHockeyNoFrameskip-v4, IceHockey-ram-v0, IceHockey-ram-v4, IceHockey-ramDeterministic-v0, IceHockey-ramDeterministic-v4, IceHockey-ramNoFrameskip-v0, IceHockey-ramNoFrameskip-v4, Jamesbond-v0, Jamesbond-v4, JamesbondDeterministic-v0, JamesbondDeterministic-v4, JamesbondNoFrameskip-v0, JamesbondNoFrameskip-v4, Jamesbond-ram-v0, Jamesbond-ram-v4, Jamesbond-ramDeterministic-v0, Jamesbond-ramDeterministic-v4, Jamesbond-ramNoFrameskip-v0, Jamesbond-ramNoFrameskip-v4, JourneyEscape-v0, JourneyEscape-v4, JourneyEscapeDeterministic-v0, JourneyEscapeDeterministic-v4, JourneyEscapeNoFrameskip-v0, JourneyEscapeNoFrameskip-v4, JourneyEscape-ram-v0, JourneyEscape-ram-v4, JourneyEscape-ramDeterministic-v0, JourneyEscape-ramDeterministic-v4, JourneyEscape-ramNoFrameskip-v0, JourneyEscape-ramNoFrameskip-v4, Kangaroo-v0, Kangaroo-v4, KangarooDeterministic-v0, KangarooDeterministic-v4, KangarooNoFrameskip-v0, KangarooNoFrameskip-v4, Kangaroo-ram-v0, Kangaroo-ram-v4, Kangaroo-ramDeterministic-v0, Kangaroo-ramDeterministic-v4, Kangaroo-ramNoFrameskip-v0, Kangaroo-ramNoFrameskip-v4, Krull-v0, Krull-v4, KrullDeterministic-v0, KrullDeterministic-v4, KrullNoFrameskip-v0, KrullNoFrameskip-v4, Krull-ram-v0, Krull-ram-v4, Krull-ramDeterministic-v0, Krull-ramDeterministic-v4, Krull-ramNoFrameskip-v0, Krull-ramNoFrameskip-v4, KungFuMaster-v0, KungFuMaster-v4, KungFuMasterDeterministic-v0, KungFuMasterDeterministic-v4, KungFuMasterNoFrameskip-v0, KungFuMasterNoFrameskip-v4, KungFuMaster-ram-v0, KungFuMaster-ram-v4, KungFuMaster-ramDeterministic-v0, KungFuMaster-ramDeterministic-v4, KungFuMaster-ramNoFrameskip-v0, KungFuMaster-ramNoFrameskip-v4, MontezumaRevenge-v0, MontezumaRevenge-v4, MontezumaRevengeDeterministic-v0, MontezumaRevengeDeterministic-v4, MontezumaRevengeNoFrameskip-v0, MontezumaRevengeNoFrameskip-v4, MontezumaRevenge-ram-v0, MontezumaRevenge-ram-v4, MontezumaRevenge-ramDeterministic-v0, MontezumaRevenge-ramDeterministic-v4, MontezumaRevenge-ramNoFrameskip-v0, MontezumaRevenge-ramNoFrameskip-v4, MsPacman-v0, MsPacman-v4, MsPacmanDeterministic-v0, MsPacmanDeterministic-v4, MsPacmanNoFrameskip-v0, MsPacmanNoFrameskip-v4, MsPacman-ram-v0, MsPacman-ram-v4, MsPacman-ramDeterministic-v0, MsPacman-ramDeterministic-v4, MsPacman-ramNoFrameskip-v0, MsPacman-ramNoFrameskip-v4, NameThisGame-v0, NameThisGame-v4, NameThisGameDeterministic-v0, NameThisGameDeterministic-v4, NameThisGameNoFrameskip-v0, NameThisGameNoFrameskip-v4, NameThisGame-ram-v0, NameThisGame-ram-v4, NameThisGame-ramDeterministic-v0, NameThisGame-ramDeterministic-v4, NameThisGame-ramNoFrameskip-v0, NameThisGame-ramNoFrameskip-v4, Phoenix-v0, Phoenix-v4, PhoenixDeterministic-v0, PhoenixDeterministic-v4, PhoenixNoFrameskip-v0, PhoenixNoFrameskip-v4, Phoenix-ram-v0, Phoenix-ram-v4, Phoenix-ramDeterministic-v0, Phoenix-ramDeterministic-v4, Phoenix-ramNoFrameskip-v0, Phoenix-ramNoFrameskip-v4, Pitfall-v0, Pitfall-v4, PitfallDeterministic-v0, PitfallDeterministic-v4, PitfallNoFrameskip-v0, PitfallNoFrameskip-v4, Pitfall-ram-v0, Pitfall-ram-v4, Pitfall-ramDeterministic-v0, Pitfall-ramDeterministic-v4, Pitfall-ramNoFrameskip-v0, Pitfall-ramNoFrameskip-v4, Pong-v0, Pong-v4, PongDeterministic-v0, PongDeterministic-v4, PongNoFrameskip-v0, PongNoFrameskip-v4, Pong-ram-v0, Pong-ram-v4, Pong-ramDeterministic-v0, Pong-ramDeterministic-v4, Pong-ramNoFrameskip-v0, Pong-ramNoFrameskip-v4, Pooyan-v0, Pooyan-v4, PooyanDeterministic-v0, PooyanDeterministic-v4, PooyanNoFrameskip-v0, PooyanNoFrameskip-v4, Pooyan-ram-v0, Pooyan-ram-v4, Pooyan-ramDeterministic-v0, Pooyan-ramDeterministic-v4, Pooyan-ramNoFrameskip-v0, Pooyan-ramNoFrameskip-v4, PrivateEye-v0, PrivateEye-v4, PrivateEyeDeterministic-v0, PrivateEyeDeterministic-v4, PrivateEyeNoFrameskip-v0, PrivateEyeNoFrameskip-v4, PrivateEye-ram-v0, PrivateEye-ram-v4, PrivateEye-ramDeterministic-v0, PrivateEye-ramDeterministic-v4, PrivateEye-ramNoFrameskip-v0, PrivateEye-ramNoFrameskip-v4, Qbert-v0, Qbert-v4, QbertDeterministic-v0, QbertDeterministic-v4, QbertNoFrameskip-v0, QbertNoFrameskip-v4, Qbert-ram-v0, Qbert-ram-v4, Qbert-ramDeterministic-v0, Qbert-ramDeterministic-v4, Qbert-ramNoFrameskip-v0, Qbert-ramNoFrameskip-v4, Riverraid-v0, Riverraid-v4, RiverraidDeterministic-v0, RiverraidDeterministic-v4, RiverraidNoFrameskip-v0, RiverraidNoFrameskip-v4, Riverraid-ram-v0, Riverraid-ram-v4, Riverraid-ramDeterministic-v0, Riverraid-ramDeterministic-v4, Riverraid-ramNoFrameskip-v0, Riverraid-ramNoFrameskip-v4, RoadRunner-v0, RoadRunner-v4, RoadRunnerDeterministic-v0, RoadRunnerDeterministic-v4, RoadRunnerNoFrameskip-v0, RoadRunnerNoFrameskip-v4, RoadRunner-ram-v0, RoadRunner-ram-v4, RoadRunner-ramDeterministic-v0, RoadRunner-ramDeterministic-v4, RoadRunner-ramNoFrameskip-v0, RoadRunner-ramNoFrameskip-v4, Robotank-v0, Robotank-v4, RobotankDeterministic-v0, RobotankDeterministic-v4, RobotankNoFrameskip-v0, RobotankNoFrameskip-v4, Robotank-ram-v0, Robotank-ram-v4, Robotank-ramDeterministic-v0, Robotank-ramDeterministic-v4, Robotank-ramNoFrameskip-v0, Robotank-ramNoFrameskip-v4, Seaquest-v0, Seaquest-v4, SeaquestDeterministic-v0, SeaquestDeterministic-v4, SeaquestNoFrameskip-v0, SeaquestNoFrameskip-v4, Seaquest-ram-v0, Seaquest-ram-v4, Seaquest-ramDeterministic-v0, Seaquest-ramDeterministic-v4, Seaquest-ramNoFrameskip-v0, Seaquest-ramNoFrameskip-v4, Skiing-v0, Skiing-v4, SkiingDeterministic-v0, SkiingDeterministic-v4, SkiingNoFrameskip-v0, SkiingNoFrameskip-v4, Skiing-ram-v0, Skiing-ram-v4, Skiing-ramDeterministic-v0, Skiing-ramDeterministic-v4, Skiing-ramNoFrameskip-v0, Skiing-ramNoFrameskip-v4, Solaris-v0, Solaris-v4, SolarisDeterministic-v0, SolarisDeterministic-v4, SolarisNoFrameskip-v0, SolarisNoFrameskip-v4, Solaris-ram-v0, Solaris-ram-v4, Solaris-ramDeterministic-v0, Solaris-ramDeterministic-v4, Solaris-ramNoFrameskip-v0, Solaris-ramNoFrameskip-v4, SpaceInvaders-v0, SpaceInvaders-v4, SpaceInvadersDeterministic-v0, SpaceInvadersDeterministic-v4, SpaceInvadersNoFrameskip-v0, SpaceInvadersNoFrameskip-v4, SpaceInvaders-ram-v0, SpaceInvaders-ram-v4, SpaceInvaders-ramDeterministic-v0, SpaceInvaders-ramDeterministic-v4, SpaceInvaders-ramNoFrameskip-v0, SpaceInvaders-ramNoFrameskip-v4, StarGunner-v0, StarGunner-v4, StarGunnerDeterministic-v0, StarGunnerDeterministic-v4, StarGunnerNoFrameskip-v0, StarGunnerNoFrameskip-v4, StarGunner-ram-v0, StarGunner-ram-v4, StarGunner-ramDeterministic-v0, StarGunner-ramDeterministic-v4, StarGunner-ramNoFrameskip-v0, StarGunner-ramNoFrameskip-v4, Tennis-v0, Tennis-v4, TennisDeterministic-v0, TennisDeterministic-v4, TennisNoFrameskip-v0, TennisNoFrameskip-v4, Tennis-ram-v0, Tennis-ram-v4, Tennis-ramDeterministic-v0, Tennis-ramDeterministic-v4, Tennis-ramNoFrameskip-v0, Tennis-ramNoFrameskip-v4, TimePilot-v0, TimePilot-v4, TimePilotDeterministic-v0, TimePilotDeterministic-v4, TimePilotNoFrameskip-v0, TimePilotNoFrameskip-v4, TimePilot-ram-v0, TimePilot-ram-v4, TimePilot-ramDeterministic-v0, TimePilot-ramDeterministic-v4, TimePilot-ramNoFrameskip-v0, TimePilot-ramNoFrameskip-v4, Tutankham-v0, Tutankham-v4, TutankhamDeterministic-v0, TutankhamDeterministic-v4, TutankhamNoFrameskip-v0, TutankhamNoFrameskip-v4, Tutankham-ram-v0, Tutankham-ram-v4, Tutankham-ramDeterministic-v0, Tutankham-ramDeterministic-v4, Tutankham-ramNoFrameskip-v0, Tutankham-ramNoFrameskip-v4, UpNDown-v0, UpNDown-v4, UpNDownDeterministic-v0, UpNDownDeterministic-v4, UpNDownNoFrameskip-v0, UpNDownNoFrameskip-v4, UpNDown-ram-v0, UpNDown-ram-v4, UpNDown-ramDeterministic-v0, UpNDown-ramDeterministic-v4, UpNDown-ramNoFrameskip-v0, UpNDown-ramNoFrameskip-v4, Venture-v0, Venture-v4, VentureDeterministic-v0, VentureDeterministic-v4, VentureNoFrameskip-v0, VentureNoFrameskip-v4, Venture-ram-v0, Venture-ram-v4, Venture-ramDeterministic-v0, Venture-ramDeterministic-v4, Venture-ramNoFrameskip-v0, Venture-ramNoFrameskip-v4, VideoPinball-v0, VideoPinball-v4, VideoPinballDeterministic-v0, VideoPinballDeterministic-v4, VideoPinballNoFrameskip-v0, VideoPinballNoFrameskip-v4, VideoPinball-ram-v0, VideoPinball-ram-v4, VideoPinball-ramDeterministic-v0, VideoPinball-ramDeterministic-v4, VideoPinball-ramNoFrameskip-v0, VideoPinball-ramNoFrameskip-v4, WizardOfWor-v0, WizardOfWor-v4, WizardOfWorDeterministic-v0, WizardOfWorDeterministic-v4, WizardOfWorNoFrameskip-v0, WizardOfWorNoFrameskip-v4, WizardOfWor-ram-v0, WizardOfWor-ram-v4, WizardOfWor-ramDeterministic-v0, WizardOfWor-ramDeterministic-v4, WizardOfWor-ramNoFrameskip-v0, WizardOfWor-ramNoFrameskip-v4, YarsRevenge-v0, YarsRevenge-v4, YarsRevengeDeterministic-v0, YarsRevengeDeterministic-v4, YarsRevengeNoFrameskip-v0, YarsRevengeNoFrameskip-v4, YarsRevenge-ram-v0, YarsRevenge-ram-v4, YarsRevenge-ramDeterministic-v0, YarsRevenge-ramDeterministic-v4, YarsRevenge-ramNoFrameskip-v0, YarsRevenge-ramNoFrameskip-v4, Zaxxon-v0, Zaxxon-v4, ZaxxonDeterministic-v0, ZaxxonDeterministic-v4, ZaxxonNoFrameskip-v0, ZaxxonNoFrameskip-v4, Zaxxon-ram-v0, Zaxxon-ram-v4, Zaxxon-ramDeterministic-v0, Zaxxon-ramDeterministic-v4, Zaxxon-ramNoFrameskip-v0, Zaxxon-ramNoFrameskip-v4, CubeCrash-v0, CubeCrashSparse-v0, CubeCrashScreenBecomesBlack-v0, MemorizeDigits-v0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"Ks_cKcq6bXeV"},"source":["## Guessing Game Environment Implementation"]},{"cell_type":"markdown","metadata":{"id":"hanJdR3h_-Li"},"source":["Let's define a simple OpenAI Gym environment for a number guessing game. In the environment, an agent has to guess a number between 0-100, by asking for a random nbr or in- or decreasing by 1 or 10, and can make observations if the guess is lower (1), equal (2) or higher (3) than the actual number.\n","The game ends when either 50 guesses were made or the guessed number is <1% off from the actual number."]},{"cell_type":"code","metadata":{"id":"QDQkWQLA5F2O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609340816654,"user_tz":-60,"elapsed":3442,"user":{"displayName":"Michael Menzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghb_AthsQBGiw6bqarv0qCUUv4_xqG97Nchzmvqjck=s64","userId":"08013474203105065423"}},"outputId":"670f6f94-96d7-438c-84bf-e58ca525c929"},"source":["class GuessingGame(gym.Env):\r\n","    \"\"\"Number guessing game\r\n","    The object of the game is to guess within 1% of the randomly chosen number\r\n","    within 50 time steps\r\n","    After each step the agent is provided with one of four possible observations\r\n","    which indicate where the guess is in relation to the randomly chosen number\r\n","    0 - No guess yet submitted (only after reset)\r\n","    1 - Guess is lower than the target\r\n","    2 - Guess is equal to the target\r\n","    3 - Guess is higher than the target\r\n","    The actions are:\r\n","    0 - Decrease number by 10\r\n","    1 - Decrease number by 1\r\n","    2 - Generate random number\r\n","    3 - Increase number by 1\r\n","    4 - Increase number by 10\r\n","    The rewards are:\r\n","    0 if the agent's guess is outside of 1% of the target\r\n","    (50 - nbr of guesses) if the agent's guess is inside 1% of the target\r\n","    The episode terminates after the agent guesses within 1% of the target or\r\n","    50 steps have been taken\r\n","    The agent will need to use a memory of previously submitted actions and observations\r\n","    in order to efficiently explore the available actions\r\n","    The purpose is to have agents optimize their exploration parameters (e.g. how far to\r\n","    explore from previous actions) based on previous experience. Because the goal changes\r\n","    each episode a state-value or action-value function isn't able to provide any additional\r\n","    benefit apart from being able to tell whether to increase or decrease the next guess.\r\n","    The perfect agent would likely learn the bounds of the action space (without referring\r\n","    to them explicitly) and then follow binary tree style exploration towards to goal number\r\n","    \"\"\"\r\n","    def __init__(self):\r\n","        self.range = 100  # Randomly selected number is within [0, this value]\r\n","        self.bounds = self.range\r\n","\r\n","        self.action_space = spaces.Discrete(5)\r\n","        #self.action_space = spaces.Box(low=0, high=self.bounds, \r\n","        #                               shape=(), dtype=np.int32)\r\n","        self.observation_space = spaces.Discrete(4)\r\n","\r\n","        self.number = 0\r\n","        self.guess_count = 0\r\n","        self.guess_max = 50\r\n","        self.observation = 0\r\n","\r\n","        self.reset()\r\n","\r\n","    def step(self, action):\r\n","        assert self.action_space.contains(action)\r\n","\r\n","        prev_guess_number = self.guess_number\r\n","\r\n","        if action == 0:\r\n","          self.guess_number -= 10\r\n","        elif action == 1:\r\n","          self.guess_number -= 1\r\n","        elif action == 2:\r\n","          self.guess_number = np.random.randint(0, self.range)\r\n","        elif action == 3:\r\n","          self.guess_number += 1\r\n","        elif action == 4:\r\n","          self.guess_number += 10\r\n","\r\n","        if self.guess_number < self.number:\r\n","            self.observation = 1\r\n","        elif self.guess_number == self.number:\r\n","            self.observation = 2\r\n","        elif self.guess_number > self.number:\r\n","            self.observation = 3\r\n","\r\n","        reward = 0\r\n","        done = False\r\n","        self.guess_count += 1\r\n","\r\n","        if (self.number - self.range * 0.01) < self.guess_number < (self.number + self.range * 0.01):\r\n","            reward = self.guess_max - self.guess_count\r\n","            done = True\r\n","        else:\r\n","          reward = 1 - (abs(self.number - self.guess_number) / abs(self.number - prev_guess_number))\r\n","\r\n","        if self.guess_count >= self.guess_max:\r\n","            done = True\r\n","\r\n","        return self.observation, reward, done, {\"number\": self.number, \"guess_number\": self.guess_number, \"guesses\": self.guess_count}\r\n","\r\n","    def reset(self):\r\n","        self.number = np.random.randint(0, self.range)\r\n","        self.guess_number = -1\r\n","        self.guess_count = 0\r\n","        self.observation = 0\r\n","        return self.observation\r\n","\r\n","env = GuessingGame()\r\n","print(f'actions: {env.action_space}, observations: {env.observation_space}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["actions: Discrete(5), observations: Discrete(4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YYDJlGKFbdv9"},"source":["## Naive Random Policy Agent"]},{"cell_type":"markdown","metadata":{"id":"SJxHpaNRAi4i"},"source":["We start with a simple implementation of a static random policy used by an agent. The agent simply loops through 50 guesses and picks a random number each time. If he is right or has reached 50 iterations, the loop stops. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bei1g2OJcMd8","executionInfo":{"status":"ok","timestamp":1609340816656,"user_tz":-60,"elapsed":1881,"user":{"displayName":"Michael Menzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghb_AthsQBGiw6bqarv0qCUUv4_xqG97Nchzmvqjck=s64","userId":"08013474203105065423"}},"outputId":"b4bad2fd-1b52-4a1c-ad21-b024c4941503"},"source":["env.reset()\r\n","done = False\r\n","while not done:\r\n","  action = env.action_space.sample()\r\n","  print(f'action: {action}')\r\n","  obs, reward, done, state = env.step(action) # take a random action\r\n","  print(f'observation: {obs}, reward: {reward}, done: {done}, state: {state}')\r\n","  if done: break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["action: 3\n","observation: 1, reward: 0.012658227848101222, done: False, state: {'number': 78, 'guess_number': 0, 'guesses': 1}\n","action: 4\n","observation: 1, reward: 0.1282051282051282, done: False, state: {'number': 78, 'guess_number': 10, 'guesses': 2}\n","action: 3\n","observation: 1, reward: 0.014705882352941124, done: False, state: {'number': 78, 'guess_number': 11, 'guesses': 3}\n","action: 2\n","observation: 1, reward: 0.28358208955223885, done: False, state: {'number': 78, 'guess_number': 30, 'guesses': 4}\n","action: 4\n","observation: 1, reward: 0.20833333333333337, done: False, state: {'number': 78, 'guess_number': 40, 'guesses': 5}\n","action: 4\n","observation: 1, reward: 0.26315789473684215, done: False, state: {'number': 78, 'guess_number': 50, 'guesses': 6}\n","action: 2\n","observation: 1, reward: -1.25, done: False, state: {'number': 78, 'guess_number': 15, 'guesses': 7}\n","action: 4\n","observation: 1, reward: 0.15873015873015872, done: False, state: {'number': 78, 'guess_number': 25, 'guesses': 8}\n","action: 0\n","observation: 1, reward: -0.18867924528301883, done: False, state: {'number': 78, 'guess_number': 15, 'guesses': 9}\n","action: 0\n","observation: 1, reward: -0.15873015873015883, done: False, state: {'number': 78, 'guess_number': 5, 'guesses': 10}\n","action: 4\n","observation: 1, reward: 0.136986301369863, done: False, state: {'number': 78, 'guess_number': 15, 'guesses': 11}\n","action: 1\n","observation: 1, reward: -0.015873015873015817, done: False, state: {'number': 78, 'guess_number': 14, 'guesses': 12}\n","action: 1\n","observation: 1, reward: -0.015625, done: False, state: {'number': 78, 'guess_number': 13, 'guesses': 13}\n","action: 4\n","observation: 1, reward: 0.15384615384615385, done: False, state: {'number': 78, 'guess_number': 23, 'guesses': 14}\n","action: 2\n","observation: 1, reward: 0.7090909090909091, done: False, state: {'number': 78, 'guess_number': 62, 'guesses': 15}\n","action: 0\n","observation: 1, reward: -0.625, done: False, state: {'number': 78, 'guess_number': 52, 'guesses': 16}\n","action: 0\n","observation: 1, reward: -0.3846153846153846, done: False, state: {'number': 78, 'guess_number': 42, 'guesses': 17}\n","action: 0\n","observation: 1, reward: -0.2777777777777777, done: False, state: {'number': 78, 'guess_number': 32, 'guesses': 18}\n","action: 2\n","observation: 1, reward: -0.15217391304347827, done: False, state: {'number': 78, 'guess_number': 25, 'guesses': 19}\n","action: 1\n","observation: 1, reward: -0.018867924528301883, done: False, state: {'number': 78, 'guess_number': 24, 'guesses': 20}\n","action: 4\n","observation: 1, reward: 0.18518518518518523, done: False, state: {'number': 78, 'guess_number': 34, 'guesses': 21}\n","action: 1\n","observation: 1, reward: -0.022727272727272707, done: False, state: {'number': 78, 'guess_number': 33, 'guesses': 22}\n","action: 4\n","observation: 1, reward: 0.2222222222222222, done: False, state: {'number': 78, 'guess_number': 43, 'guesses': 23}\n","action: 0\n","observation: 1, reward: -0.2857142857142858, done: False, state: {'number': 78, 'guess_number': 33, 'guesses': 24}\n","action: 3\n","observation: 1, reward: 0.022222222222222254, done: False, state: {'number': 78, 'guess_number': 34, 'guesses': 25}\n","action: 4\n","observation: 1, reward: 0.2272727272727273, done: False, state: {'number': 78, 'guess_number': 44, 'guesses': 26}\n","action: 3\n","observation: 1, reward: 0.02941176470588236, done: False, state: {'number': 78, 'guess_number': 45, 'guesses': 27}\n","action: 2\n","observation: 3, reward: 0.8484848484848485, done: False, state: {'number': 78, 'guess_number': 83, 'guesses': 28}\n","action: 0\n","observation: 1, reward: 0.0, done: False, state: {'number': 78, 'guess_number': 73, 'guesses': 29}\n","action: 1\n","observation: 1, reward: -0.19999999999999996, done: False, state: {'number': 78, 'guess_number': 72, 'guesses': 30}\n","action: 3\n","observation: 1, reward: 0.16666666666666663, done: False, state: {'number': 78, 'guess_number': 73, 'guesses': 31}\n","action: 4\n","observation: 3, reward: 0.0, done: False, state: {'number': 78, 'guess_number': 83, 'guesses': 32}\n","action: 2\n","observation: 3, reward: 0.8, done: False, state: {'number': 78, 'guess_number': 79, 'guesses': 33}\n","action: 2\n","observation: 1, reward: -72.0, done: False, state: {'number': 78, 'guess_number': 5, 'guesses': 34}\n","action: 1\n","observation: 1, reward: -0.013698630136986356, done: False, state: {'number': 78, 'guess_number': 4, 'guesses': 35}\n","action: 0\n","observation: 1, reward: -0.1351351351351351, done: False, state: {'number': 78, 'guess_number': -6, 'guesses': 36}\n","action: 1\n","observation: 1, reward: -0.011904761904761862, done: False, state: {'number': 78, 'guess_number': -7, 'guesses': 37}\n","action: 2\n","observation: 1, reward: 0.6352941176470588, done: False, state: {'number': 78, 'guess_number': 47, 'guesses': 38}\n","action: 1\n","observation: 1, reward: -0.032258064516129004, done: False, state: {'number': 78, 'guess_number': 46, 'guesses': 39}\n","action: 1\n","observation: 1, reward: -0.03125, done: False, state: {'number': 78, 'guess_number': 45, 'guesses': 40}\n","action: 2\n","observation: 1, reward: -0.21212121212121215, done: False, state: {'number': 78, 'guess_number': 38, 'guesses': 41}\n","action: 0\n","observation: 1, reward: -0.25, done: False, state: {'number': 78, 'guess_number': 28, 'guesses': 42}\n","action: 2\n","observation: 1, reward: 0.14, done: False, state: {'number': 78, 'guess_number': 35, 'guesses': 43}\n","action: 4\n","observation: 1, reward: 0.2325581395348837, done: False, state: {'number': 78, 'guess_number': 45, 'guesses': 44}\n","action: 0\n","observation: 1, reward: -0.303030303030303, done: False, state: {'number': 78, 'guess_number': 35, 'guesses': 45}\n","action: 1\n","observation: 1, reward: -0.023255813953488413, done: False, state: {'number': 78, 'guess_number': 34, 'guesses': 46}\n","action: 1\n","observation: 1, reward: -0.022727272727272707, done: False, state: {'number': 78, 'guess_number': 33, 'guesses': 47}\n","action: 2\n","observation: 1, reward: -0.0888888888888888, done: False, state: {'number': 78, 'guess_number': 29, 'guesses': 48}\n","action: 0\n","observation: 1, reward: -0.20408163265306123, done: False, state: {'number': 78, 'guess_number': 19, 'guesses': 49}\n","action: 0\n","observation: 1, reward: -0.1694915254237288, done: True, state: {'number': 78, 'guess_number': 9, 'guesses': 50}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9WTucYTQFZph"},"source":["## DQN Agent with TF-Agents"]},{"cell_type":"markdown","metadata":{"id":"d47aJFBpCs-K"},"source":["### Convert the OpenAI Gym Environment to TF Agents"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AhC_OfSXCx2q","executionInfo":{"status":"ok","timestamp":1609340817052,"user_tz":-60,"elapsed":419,"user":{"displayName":"Michael Menzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghb_AthsQBGiw6bqarv0qCUUv4_xqG97Nchzmvqjck=s64","userId":"08013474203105065423"}},"outputId":"386c8b50-bf4a-4998-e32f-ce703e6297e0"},"source":["tf_env = tf_py_environment.TFPyEnvironment(suite_gym.wrap_env(env, max_episode_steps=env.guess_max))\n","print(f'actions: {tf_env.action_spec()}')\n","print(f'observations: {tf_env.observation_spec()}')\n","print(f'timespec: {tf_env.time_step_spec()}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["actions: BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0), maximum=array(4))\n","observations: BoundedTensorSpec(shape=(), dtype=tf.int64, name='observation', minimum=array(0), maximum=array(3))\n","timespec: TimeStep(step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(), dtype=tf.float32, name='reward'), discount=BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)), observation=BoundedTensorSpec(shape=(), dtype=tf.int64, name='observation', minimum=array(0), maximum=array(3)))\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5cXwtsSUbiqk"},"source":["### Instantiate a DQN Agent"]},{"cell_type":"code","metadata":{"id":"G5-wxOwFe4BB"},"source":["q_net = q_network.QNetwork(\r\n","  tf_env.observation_spec(),\r\n","  tf_env.action_spec()    \r\n",")\r\n","\r\n","## Optional: Use a RNN-based QNetwork\r\n","q_rnn_net = q_rnn_network.QRnnNetwork(\r\n","  tf_env.observation_spec(),\r\n","  tf_env.action_spec(),\r\n","  lstm_size=[150])\r\n","\r\n","agent = dqn_agent.DqnAgent(\r\n","    tf_env.time_step_spec(),\r\n","    tf_env.action_spec(),\r\n","# Optional: Replace here with a RNN-based QNetwork\r\n","    q_network=q_net,\r\n","    optimizer=tf.keras.optimizers.Adam(),\r\n","    epsilon_greedy=.1,\r\n","    td_errors_loss_fn=common.element_wise_squared_loss,\r\n","    train_step_counter=tf.Variable(0),\r\n","    debug_summaries=True,\r\n","    summarize_grads_and_vars=True)\r\n","\r\n","agent.initialize()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dq1e7OiRBXqs"},"source":["### Replay Buffer"]},{"cell_type":"markdown","metadata":{"id":"AcvoWf_yBc2i"},"source":["We istantiate a replay buffer which stores experiences made by an agent. The buffer helps us replay past observations and train agents based on that data.\n","This helps when using agent A to make experiences and then use the data to train agent B."]},{"cell_type":"code","metadata":{"id":"UQPUy8F9jDtr"},"source":["replay_buffer_capacity = env.guess_max*10\r\n","\r\n","replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\r\n","    agent.collect_data_spec,\r\n","    batch_size=tf_env.batch_size,\r\n","    max_length=replay_buffer_capacity)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vYJvy02MDGeq"},"source":["### Training Loop"]},{"cell_type":"markdown","metadata":{"id":"idISZx0DDxWf"},"source":["We use a ```DynamicStepDriver``` to run the agent's collect policy for ```collect_steps``` steps and store the trajectories (experiences) in the replay buffer.\n","We then train our ```QNetwork``` with the trajectories (and smooth with a target ```QNetwork```) which calculates favorable actions using q-values. The favorable actions are then considered as part of a greedy policy."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZCqGAbQLs1GT","executionInfo":{"status":"ok","timestamp":1609341038727,"user_tz":-60,"elapsed":215909,"user":{"displayName":"Michael Menzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghb_AthsQBGiw6bqarv0qCUUv4_xqG97Nchzmvqjck=s64","userId":"08013474203105065423"}},"outputId":"671f0564-03e0-46d0-ac56-dfb4d2468c4a"},"source":["iterations = 10\r\n","collect_steps = replay_buffer_capacity\r\n","\r\n","# metrics\r\n","avgReturn = AverageReturnMetric()\r\n","avgLength = AverageEpisodeLengthMetric()\r\n","actionHist = ChosenActionHistogram()\r\n","nbrEpisodes = NumberOfEpisodes()\r\n","metrics = [avgLength, avgReturn, nbrEpisodes]\r\n","\r\n","observers = metrics + [replay_buffer.add_batch]\r\n","\r\n","for iteration in range(iterations):\r\n","\r\n","  # Collect trajectories with a driver\r\n","  dynamic_step_driver.DynamicStepDriver(\r\n","    tf_env,\r\n","    agent.collect_policy,\r\n","    observers=observers,\r\n","    num_steps=collect_steps).run()\r\n","  \r\n","  # DQN agent require 2 steps (current and next) or more (n_steps+1) to calculate loss\r\n","  data_iterator = iter(replay_buffer.as_dataset(\r\n","      num_parallel_calls=3, sample_batch_size=10, num_steps=2)\r\n","    .prefetch(3))\r\n","\r\n","  # Train the DQN agent\r\n","  for i in range(collect_steps):\r\n","    trajectories, _ = next(data_iterator)\r\n","    loss, extra = agent.train(experience=trajectories)\r\n","    #print(f'step: {agent.train_step_counter.numpy()}, loss: {loss}')\r\n","    #print(f'td_loss: {extra.td_loss}')\r\n","\r\n","  print(f'iteration: {iteration}, avg return: {avgReturn.result()}, avg length: {avgLength.result()}, # episodes: {nbrEpisodes.result()}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_agents/drivers/dynamic_step_driver.py:203: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.while_loop(c, b, vars, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_agents/drivers/dynamic_step_driver.py:203: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.while_loop(c, b, vars, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py:1218: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `as_dataset(..., single_deterministic_pass=False) instead.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py:1218: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `as_dataset(..., single_deterministic_pass=False) instead.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.foldr(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.foldr(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"],"name":"stderr"},{"output_type":"stream","text":["iteration: 0, avg return: 9.885412216186523, avg length: 40.20000076293945, # episodes: 11\n","iteration: 1, avg return: -102.15940856933594, avg length: 45.0, # episodes: 23\n","iteration: 2, avg return: 6.598444938659668, avg length: 43.29999923706055, # episodes: 35\n","iteration: 3, avg return: -5.836390495300293, avg length: 50.0, # episodes: 45\n","iteration: 4, avg return: 18.867826461791992, avg length: 32.79999923706055, # episodes: 59\n","iteration: 5, avg return: -4.253633975982666, avg length: 46.099998474121094, # episodes: 70\n","iteration: 6, avg return: 1.2619245052337646, avg length: 46.70000076293945, # episodes: 81\n","iteration: 7, avg return: 12.12291145324707, avg length: 39.0, # episodes: 93\n","iteration: 8, avg return: -2.7912871837615967, avg length: 45.70000076293945, # episodes: 104\n","iteration: 9, avg return: -1.1686832904815674, avg length: 45.900001525878906, # episodes: 115\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j_xkpj7-FQCK"},"source":["### Test the DQN Agent's Learned Policy"]},{"cell_type":"code","metadata":{"id":"z2VPyY8stbJO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609341039071,"user_tz":-60,"elapsed":203270,"user":{"displayName":"Michael Menzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghb_AthsQBGiw6bqarv0qCUUv4_xqG97Nchzmvqjck=s64","userId":"08013474203105065423"}},"outputId":"83742857-64ea-40e9-dd1b-71d3f42f0c71"},"source":["tf_env.reset()\r\n","\r\n","def log_eval(traj):\r\n","  print(f'observation: {traj.observation}, action: {traj.action}, reward: {traj.reward}')\r\n","\r\n","time_step, policy_state = dynamic_step_driver.DynamicStepDriver(\r\n","    tf_env,\r\n","    agent.policy,\r\n","    observers=[log_eval],\r\n","    num_steps=env.guess_max).run()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["observation: [0], action: [2], reward: [0.61702126]\n","observation: [1], action: [2], reward: [0.]\n","observation: [1], action: [2], reward: [-0.30555555]\n","observation: [1], action: [2], reward: [0.80851066]\n","observation: [1], action: [2], reward: [-8.444445]\n","observation: [1], action: [2], reward: [0.25882354]\n","observation: [1], action: [2], reward: [0.3968254]\n","observation: [1], action: [2], reward: [-1.2105263]\n","observation: [1], action: [2], reward: [0.05952381]\n","observation: [1], action: [2], reward: [0.9493671]\n","observation: [3], action: [2], reward: [-19.]\n","observation: [1], action: [2], reward: [0.2125]\n","observation: [1], action: [2], reward: [0.7936508]\n","observation: [1], action: [2], reward: [-5.769231]\n","observation: [1], action: [2], reward: [0.4318182]\n","observation: [1], action: [2], reward: [-0.38]\n","observation: [1], action: [2], reward: [0.85507244]\n","observation: [1], action: [2], reward: [-6.9]\n","observation: [1], action: [2], reward: [0.835443]\n","observation: [1], action: [2], reward: [0.7692308]\n","observation: [1], action: [2], reward: [-15.]\n","observation: [1], action: [2], reward: [0.]\n","observation: [1], action: [2], reward: [0.625]\n","observation: [1], action: [2], reward: [-3.8333333]\n","observation: [1], action: [2], reward: [0.4597701]\n","observation: [1], action: [2], reward: [0.61702126]\n","observation: [1], action: [2], reward: [0.7777778]\n","observation: [3], action: [2], reward: [-11.25]\n","observation: [1], action: [2], reward: [21.]\n","observation: [2], action: [2], reward: [0.]\n","observation: [0], action: [2], reward: [0.8888889]\n","observation: [3], action: [2], reward: [-3.2]\n","observation: [1], action: [2], reward: [0.1904762]\n","observation: [1], action: [2], reward: [0.29411766]\n","observation: [1], action: [2], reward: [0.9583333]\n","observation: [1], action: [2], reward: [-76.]\n","observation: [1], action: [2], reward: [0.5064935]\n","observation: [1], action: [2], reward: [0.7631579]\n","observation: [3], action: [2], reward: [-5.888889]\n","observation: [1], action: [2], reward: [0.4032258]\n","observation: [1], action: [2], reward: [-1.3243244]\n","observation: [1], action: [2], reward: [0.627907]\n","observation: [1], action: [2], reward: [-0.875]\n","observation: [1], action: [2], reward: [0.93333334]\n","observation: [1], action: [2], reward: [-12.5]\n","observation: [1], action: [2], reward: [0.8703704]\n","observation: [1], action: [2], reward: [-2.4285715]\n","observation: [1], action: [2], reward: [0.8333333]\n","observation: [3], action: [2], reward: [-15.]\n","observation: [1], action: [2], reward: [-0.078125]\n","observation: [1], action: [2], reward: [0.1884058]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GFzRu4SfMW-K"},"source":["## PPO Agent with TF-Agents\n"]},{"cell_type":"code","metadata":{"id":"rVwyuHaJd4jN"},"source":["actor_net = actor_distribution_network.ActorDistributionNetwork(\n","  tf_env.observation_spec(),\n","  tf_env.action_spec(),\n","  #preprocessing_layers=tf.keras.layers.Lambda(lambda x: x/tf_env.observation_spec().maximum)\n",")\n","\n","value_net = value_network.ValueNetwork(\n","  tf_env.observation_spec()\n",")\n","\n","ppo_agent = PPOAgent(\n","    tf_env.time_step_spec(),\n","    tf_env.action_spec(),\n","    actor_net=actor_net,\n","    value_net=value_net,\n","    optimizer=tf.keras.optimizers.Adam(),\n","    normalize_observations=False,\n","    train_step_counter=tf.Variable(0),\n","    debug_summaries=True,\n","    summarize_grads_and_vars=True)\n","\n","ppo_agent.initialize()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nHJMqtanOrid"},"source":["ppo_replay_buffer_capacity = env.guess_max*10\n","\n","ppo_replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n","    ppo_agent.collect_data_spec,\n","    batch_size=tf_env.batch_size,\n","    max_length=ppo_replay_buffer_capacity)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kCJ9BFEsO-wI","executionInfo":{"status":"ok","timestamp":1609344230114,"user_tz":-60,"elapsed":2950344,"user":{"displayName":"Michael Menzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghb_AthsQBGiw6bqarv0qCUUv4_xqG97Nchzmvqjck=s64","userId":"08013474203105065423"}},"outputId":"c2508164-0e92-4f1f-ab5c-49d12f040053"},"source":["iterations = 10\n","collect_steps = ppo_replay_buffer_capacity\n","\n","# metrics\n","avgReturn = AverageReturnMetric()\n","avgLength = AverageEpisodeLengthMetric()\n","actionHist = ChosenActionHistogram()\n","nbrEpisodes = NumberOfEpisodes()\n","metrics = [avgLength, avgReturn, nbrEpisodes]\n","\n","observers = metrics + [ppo_replay_buffer.add_batch]\n","\n","for iteration in range(iterations):\n","\n","  # Collect trajectories with a driver\n","  dynamic_step_driver.DynamicStepDriver(\n","    tf_env,\n","    ppo_agent.collect_policy,\n","    observers=observers,\n","    num_steps=collect_steps).run()\n","  \n","  # PPO agent require 2 steps (current and next) or more (n_steps+1) to calculate loss\n","  data_iterator = iter(ppo_replay_buffer.as_dataset(\n","      num_parallel_calls=3, sample_batch_size=10, num_steps=2)\n","    .prefetch(3))\n","\n","  # Train the PPO agent\n","  for i in range(collect_steps):\n","    trajectories, _ = next(data_iterator)\n","    loss, extra = ppo_agent.train(experience=trajectories)\n","    #print(f'step: {agent.train_step_counter.numpy()}, loss: {loss}')\n","    #print(f'td_loss: {extra.td_loss}')\n","\n","  print(f'iteration: {iteration}, avg return: {avgReturn.result()}, avg length: {avgLength.result()}, # episodes: {nbrEpisodes.result()}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["iteration: 0, avg return: -10.359271049499512, avg length: 39.70000076293945, # episodes: 12\n","iteration: 1, avg return: 3.7636241912841797, avg length: 36.0, # episodes: 25\n","iteration: 2, avg return: 1.787976861000061, avg length: 35.900001525878906, # episodes: 39\n","iteration: 3, avg return: -2.353590250015259, avg length: 40.70000076293945, # episodes: 52\n","iteration: 4, avg return: -8.858983993530273, avg length: 44.900001525878906, # episodes: 64\n","iteration: 5, avg return: -22.469585418701172, avg length: 44.099998474121094, # episodes: 75\n","iteration: 6, avg return: 8.307008743286133, avg length: 32.099998474121094, # episodes: 92\n","iteration: 7, avg return: 12.121256828308105, avg length: 27.899999618530273, # episodes: 106\n","iteration: 8, avg return: -4.355345249176025, avg length: 31.600000381469727, # episodes: 121\n","iteration: 9, avg return: 7.595143795013428, avg length: 29.5, # episodes: 136\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKLRwCO3PxQz","executionInfo":{"status":"ok","timestamp":1609344231189,"user_tz":-60,"elapsed":1048,"user":{"displayName":"Michael Menzel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghb_AthsQBGiw6bqarv0qCUUv4_xqG97Nchzmvqjck=s64","userId":"08013474203105065423"}},"outputId":"d1f87d78-7125-415e-bed8-eb8774188300"},"source":["tf_env.reset()\n","\n","def log_eval(traj):\n","  print(f'observation: {traj.observation}, action: {traj.action}, reward: {traj.reward}')\n","\n","time_step, policy_state = dynamic_step_driver.DynamicStepDriver(\n","    tf_env,\n","    ppo_agent.policy,\n","    observers=[log_eval],\n","    num_steps=env.guess_max).run()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["observation: [0], action: [4], reward: [0.11494253]\n","observation: [1], action: [4], reward: [0.12987013]\n","observation: [1], action: [4], reward: [0.14925373]\n","observation: [1], action: [4], reward: [0.1754386]\n","observation: [1], action: [4], reward: [0.21276596]\n","observation: [1], action: [4], reward: [0.27027026]\n","observation: [1], action: [4], reward: [0.37037036]\n","observation: [1], action: [4], reward: [0.5882353]\n","observation: [1], action: [4], reward: [0.5714286]\n","observation: [3], action: [1], reward: [0.33333334]\n","observation: [3], action: [1], reward: [0.5]\n","observation: [3], action: [1], reward: [38.]\n","observation: [2], action: [1], reward: [0.]\n","observation: [0], action: [4], reward: [0.24390244]\n","observation: [1], action: [4], reward: [0.32258064]\n","observation: [1], action: [4], reward: [0.47619048]\n","observation: [1], action: [4], reward: [0.90909094]\n","observation: [1], action: [4], reward: [-8.]\n","observation: [3], action: [1], reward: [0.11111111]\n","observation: [3], action: [1], reward: [0.125]\n","observation: [3], action: [1], reward: [0.14285715]\n","observation: [3], action: [1], reward: [0.16666667]\n","observation: [3], action: [1], reward: [0.2]\n","observation: [3], action: [1], reward: [0.25]\n","observation: [3], action: [1], reward: [0.33333334]\n","observation: [3], action: [1], reward: [0.5]\n","observation: [3], action: [1], reward: [36.]\n","observation: [2], action: [1], reward: [0.]\n","observation: [0], action: [4], reward: [0.5555556]\n","observation: [1], action: [4], reward: [0.75]\n","observation: [3], action: [1], reward: [0.5]\n","observation: [3], action: [1], reward: [46.]\n","observation: [2], action: [1], reward: [0.]\n","observation: [0], action: [4], reward: [0.11494253]\n","observation: [1], action: [4], reward: [0.12987013]\n","observation: [1], action: [4], reward: [0.14925373]\n","observation: [1], action: [4], reward: [0.1754386]\n","observation: [1], action: [4], reward: [0.21276596]\n","observation: [1], action: [4], reward: [0.27027026]\n","observation: [1], action: [4], reward: [0.37037036]\n","observation: [1], action: [4], reward: [0.5882353]\n","observation: [1], action: [4], reward: [0.5714286]\n","observation: [3], action: [1], reward: [0.33333334]\n","observation: [3], action: [1], reward: [0.5]\n","observation: [3], action: [1], reward: [38.]\n","observation: [2], action: [1], reward: [0.]\n","observation: [0], action: [4], reward: [0.16393442]\n","observation: [1], action: [4], reward: [0.19607843]\n","observation: [1], action: [4], reward: [0.24390244]\n","observation: [1], action: [4], reward: [0.32258064]\n","observation: [1], action: [4], reward: [0.47619048]\n","observation: [1], action: [4], reward: [0.90909094]\n","observation: [1], action: [4], reward: [-8.]\n","observation: [3], action: [1], reward: [0.11111111]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tWsey4_1dWln"},"source":[""],"execution_count":null,"outputs":[]}]}