{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":19447,"status":"ok","timestamp":1654183327291,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"},"user_tz":-120},"id":"xiSy73MAmMPE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dfb72ed0-610b-4aab-ba62-bba2c86f5b52"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 4.3 MB 9.4 MB/s \n","\u001b[K     |████████████████████████████████| 4.3 MB 39.8 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 39.6 MB/s \n","\u001b[K     |████████████████████████████████| 646 kB 68.9 MB/s \n","\u001b[K     |████████████████████████████████| 281 kB 71.0 MB/s \n","\u001b[K     |████████████████████████████████| 98 kB 6.8 MB/s \n","\u001b[?25h  Building wheel for OpenEXR (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q --upgrade tensorflow-graphics tensorflow-datasets\n","!pip install -q trimesh"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":449141,"status":"ok","timestamp":1654183776428,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"},"user_tz":-120},"id":"97fZIp1uluJw"},"outputs":[],"source":["import numpy as np\n","\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import tensorflow_graphics as tfg\n","\n","from tensorflow_graphics.datasets.shapenet import Shapenet\n","from tensorflow_graphics.geometry.representation.mesh import utils as mesh_utils\n","from tensorflow_graphics.nn.layer.graph_convolution import FeatureSteeredConvolutionKerasLayer\n","from tensorflow_graphics.notebooks import mesh_segmentation_dataio as mseg_dio\n","\n","import trimesh\n","\n","from google.colab import auth\n","auth.authenticate_user()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4597,"status":"ok","timestamp":1654183781022,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"},"user_tz":-120},"id":"49rzyScMmBGb"},"outputs":[],"source":["(ds_train, ds_val, ds_test), info = Shapenet.load(split=['train', 'validation', 'test'], data_dir='gs://shapenet-dataset-eu/prepared/', with_info=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1654183781022,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"},"user_tz":-120},"id":"IlkPzHKtnjYC","outputId":"5ffafd13-6f6a-4fc2-d4bb-4546a000af41"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PrefetchDataset element_spec={'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'model_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'trimesh': {'faces': TensorSpec(shape=(None, 3), dtype=tf.uint64, name=None), 'vertices': TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)}}>"]},"metadata":{},"execution_count":5}],"source":["ds_test"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1654183781023,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"},"user_tz":-120},"id":"RMUqE-Raqtfb","outputId":"1a4afd06-6932-49ec-c4cd-0c3f0a151102"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tfds.core.DatasetInfo(\n","    name='shapenet',\n","    full_name='shapenet/shapenet_trimesh/1.0.0',\n","    description=\"\"\"\n","    ShapeNetCore is a densely annotated subset of ShapeNet covering 55 common object\n","    categories with ~51,300 unique 3D models. Each model in ShapeNetCore is linked\n","    to an appropriate synset in WordNet (version 3.0).\n","    \n","    The synsets will be extracted from the taxonomy.json file in the ShapeNetCore.v2.zip\n","    archive and the splits from http://shapenet.cs.stanford.edu/shapenet/obj-zip/SHREC16/all.csv\n","    \"\"\",\n","    config_description=\"\"\"\n","    \n","    ShapeNetCore is a densely annotated subset of ShapeNet covering 55 common object\n","    categories with ~51,300 unique 3D models. Each model in ShapeNetCore is linked\n","    to an appropriate synset in WordNet (version 3.0).\n","    \n","    The synsets will be extracted from the taxonomy.json file in the ShapeNetCore.v2.zip\n","    archive and the splits from http://shapenet.cs.stanford.edu/shapenet/obj-zip/SHREC16/all.csv\n","    \n","    \"\"\",\n","    homepage='https://shapenet.org/',\n","    data_path='gs://shapenet-dataset-eu/prepared/shapenet/shapenet_trimesh/1.0.0',\n","    file_format=tfrecord,\n","    download_size=3.10 MiB,\n","    dataset_size=26.01 GiB,\n","    features=FeaturesDict({\n","        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=353),\n","        'model_id': Text(shape=(), dtype=tf.string),\n","        'trimesh': TriangleMesh({\n","            'faces': Tensor(shape=(None, 3), dtype=tf.uint64),\n","            'vertices': Tensor(shape=(None, 3), dtype=tf.float32),\n","        }),\n","    }),\n","    supervised_keys=('trimesh', 'label'),\n","    disable_shuffling=False,\n","    splits={\n","        'test': <SplitInfo num_examples=10261, num_shards=64>,\n","        'train': <SplitInfo num_examples=35708, num_shards=256>,\n","        'validation': <SplitInfo num_examples=5158, num_shards=32>,\n","    },\n","    citation=\"\"\"@techreport{shapenet2015,\n","      title       = {{ShapeNet: An Information-Rich 3D Model Repository}},\n","      author      = {Chang, Angel X. and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and Xiao, Jianxiong and Yi, Li and Yu, Fisher},\n","      number      = {arXiv:1512.03012 [cs.GR]},\n","      institution = {Stanford University --- Princeton University --- Toyota Technological Institute at Chicago},\n","      year        = {2015}\n","    }\"\"\",\n",")"]},"metadata":{},"execution_count":6}],"source":["info"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":559,"output_embedded_package_id":"16dQBtkDHy1xgKuhaV21KRk6CaxuuZozP"},"executionInfo":{"elapsed":11364,"status":"ok","timestamp":1654183821272,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"},"user_tz":-120},"id":"T9RptRBGo5Ds","outputId":"8e484100-e064-4a8e-a24a-8f94d962f96b"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["for ex in ds_train.take(1):\n","  trio = trimesh.Trimesh(ex['trimesh']['vertices'], ex['trimesh']['faces'])\n","  print(ex['label'])\n","\n","trio.show()"]},{"cell_type":"markdown","metadata":{"id":"d4Auvona1QG6"},"source":["## Dataset Preparation"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1654091802819,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"},"user_tz":-120},"id":"_cKsPLJf27U6"},"outputs":[],"source":["MAX_VERTICES = 1000\n","BATCH_SIZE = 8\n","\n","ds_train = ds_train.filter(lambda x: tf.shape(x['trimesh']['vertices'])[0] < MAX_VERTICES)\n","ds_val = ds_val.filter(lambda x: tf.shape(x['trimesh']['vertices'])[0] < MAX_VERTICES)\n","ds_test = ds_test.filter(lambda x: tf.shape(x['trimesh']['vertices'])[0] < MAX_VERTICES)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GTcP6NMCw_Ee","executionInfo":{"status":"ok","timestamp":1654092006923,"user_tz":-120,"elapsed":204118,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"}},"outputId":"db5c60ae-f7f3-4c98-debe-d0f3a809804a"},"outputs":[{"output_type":"stream","name":"stdout","text":["We construct our model for a target size of 999 vertices.\n"]}],"source":["def maximum(x, y):\n","    return tf.math.maximum(tf.cast(tf.shape(y['trimesh']['vertices'])[0], tf.float32), x)\n","\n","def minimum(x, y):\n","    return tf.math.minimum(tf.cast(tf.shape(y['trimesh']['vertices'])[0], tf.float32), x)\n","\n","max_num_vertices = (ds_train\n","                    .concatenate(ds_val)\n","                    .concatenate(ds_test)\n","                    .reduce(0., maximum).numpy().astype(np.int32))\n","\n","#min_num_vertices = (ds_train\n","#                    .concatenate(ds_val)\n","#                    .concatenate(ds_test)\n","#                    .reduce(float('inf'), minimum).numpy().astype(np.int32))\n","print(f\"We construct our model for a target size of {max_num_vertices} vertices.\")"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"QmZjy_MM3SUk","executionInfo":{"status":"ok","timestamp":1654092009450,"user_tz":-120,"elapsed":2539,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"}}},"outputs":[],"source":["@tf.function\n","def unique_edges(faces, directed_edges=True):\n","    faces_typed = tf.cast(faces, tf.int32)\n","    edges = tf.concat([faces_typed[:, 0:2], \n","                       faces_typed[:, 1:3], \n","                       tf.gather(faces_typed, [2, 0], axis=-1)],\n","                      axis=0)\n","    if directed_edges:\n","        edges = tf.concat([edges, tf.reverse(edges, axis=[-1])], axis=0)\n","    return edges\n","\n","@tf.function\n","def calculate_neighbors(ex):\n","    output = {\n","        'trimesh': {\n","            'faces': ex['trimesh']['faces'],\n","            'vertices': ex['trimesh']['vertices']\n","        },\n","        'model_id': ex['model_id'],\n","        'label': ex['label']\n","    }\n","    faces = tf.cast(ex['trimesh']['faces'], tf.int64)\n","    num_vertices = tf.expand_dims(tf.shape(ex['trimesh']['vertices'])[-2], axis=0)\n","    edges = tf.expand_dims(unique_edges(ex['trimesh']['faces']), axis=0)\n","    num_edges = tf.expand_dims(tf.shape(edges)[-2], axis=0)\n","    weights = tf.cast(tf.ones(tf.shape(edges)[:-1]), tf.float32)\n","    neighbors = mseg_dio.adjacency_from_edges(edges, weights, num_edges, num_vertices)\n","    output['trimesh']['neighbors'] = tf.sparse.reshape(neighbors, tf.shape(neighbors)[-2:])\n","    \n","    return output\n","\n","def pad_vertices(input):\n","    return tf.pad(input,  [[0, max_num_vertices - tf.shape(input)[0]], [0, 0]])\n","\n","@tf.function\n","def extract_features(ex):\n","    #'faces': ex['trimesh']['faces']\n","    return ({'vertices': pad_vertices(ex['trimesh']['vertices']), 'neighbors': ex['trimesh']['neighbors']}, ex['label'])\n","\n","\n","data_train = (ds_train\n","            .map(calculate_neighbors, num_parallel_calls=tf.data.AUTOTUNE)  \n","            .map(extract_features, num_parallel_calls=tf.data.AUTOTUNE)\n","            .batch(BATCH_SIZE, drop_remainder=True)\n","            .prefetch(tf.data.AUTOTUNE))\n","\n","data_val = (ds_val\n","            .map(calculate_neighbors, num_parallel_calls=tf.data.AUTOTUNE)  \n","            .map(extract_features, num_parallel_calls=tf.data.AUTOTUNE)\n","            .batch(BATCH_SIZE, drop_remainder=True)\n","            .prefetch(tf.data.AUTOTUNE))\n","\n","data_test = (ds_test\n","            .map(calculate_neighbors, num_parallel_calls=tf.data.AUTOTUNE)  \n","            .map(extract_features, num_parallel_calls=tf.data.AUTOTUNE)\n","            .batch(BATCH_SIZE, drop_remainder=True)\n","            .prefetch(tf.data.AUTOTUNE))"]},{"cell_type":"markdown","metadata":{"id":"f43ThKe6u8kB"},"source":["## PointNet Example"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1654092009451,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"},"user_tz":-120},"id":"2EL4JpdxqVFJ"},"outputs":[],"source":["def conv_bn(x, filters):\n","    x = tf.keras.layers.Conv1D(filters, kernel_size=1, padding='valid')(x)\n","    x = tf.keras.layers.BatchNormalization(momentum=0.0)(x)\n","    return tf.keras.layers.ReLU()(x)\n","\n","\n","def dense_bn(x, filters):\n","    x = tf.keras.layers.Dense(filters)(x)\n","    x = tf.keras.layers.BatchNormalization(momentum=0.0)(x)\n","    return tf.keras.layers.ReLU()(x)\n","\n","\n","def create_pointnet_model(conv_filters=[32, 32, 32, 64, 512], conv_filter_factor=1, dense_hidden_units=256, dropout=.1):\n","    inputs = tf.keras.Input(shape=(max_num_vertices, 3), name='vertices')\n","    \n","    x = conv_bn(inputs, int(conv_filters[0]*conv_filter_factor))\n","    for filters in conv_filters[1:]:\n","        x = conv_bn(x, int(filters*conv_filter_factor))\n","        \n","    x = tf.keras.layers.GlobalMaxPooling1D()(x)\n","    x = dense_bn(x, dense_hidden_units)\n","    x = tf.keras.layers.Dropout(dropout)(x)\n","    x = dense_bn(x, dense_hidden_units // 2)\n","    x = tf.keras.layers.Dropout(dropout)(x)\n","\n","    outputs = tf.keras.layers.Dense(info.features['label'].num_classes)(x)\n","\n","    model = tf.keras.models.Model(inputs=[inputs], outputs=[outputs])\n","    return model"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":292,"status":"ok","timestamp":1654092112689,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"},"user_tz":-120},"id":"aD02HYfZvEVK","outputId":"e8ac2ad8-4167-4a2e-8890-b71acc4fa28a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vertices (InputLayer)       [(None, 999, 3)]          0         \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 999, 32)           128       \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 999, 32)          128       \n"," hNormalization)                                                 \n","                                                                 \n"," re_lu_5 (ReLU)              (None, 999, 32)           0         \n","                                                                 \n"," conv1d_4 (Conv1D)           (None, 999, 64)           2112      \n","                                                                 \n"," batch_normalization_6 (Batc  (None, 999, 64)          256       \n"," hNormalization)                                                 \n","                                                                 \n"," re_lu_6 (ReLU)              (None, 999, 64)           0         \n","                                                                 \n"," global_max_pooling1d_1 (Glo  (None, 64)               0         \n"," balMaxPooling1D)                                                \n","                                                                 \n"," dense_3 (Dense)             (None, 64)                4160      \n","                                                                 \n"," batch_normalization_7 (Batc  (None, 64)               256       \n"," hNormalization)                                                 \n","                                                                 \n"," re_lu_7 (ReLU)              (None, 64)                0         \n","                                                                 \n"," dropout_2 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_4 (Dense)             (None, 32)                2080      \n","                                                                 \n"," batch_normalization_8 (Batc  (None, 32)               128       \n"," hNormalization)                                                 \n","                                                                 \n"," re_lu_8 (ReLU)              (None, 32)                0         \n","                                                                 \n"," dropout_3 (Dropout)         (None, 32)                0         \n","                                                                 \n"," dense_5 (Dense)             (None, 353)               11649     \n","                                                                 \n","=================================================================\n","Total params: 20,897\n","Trainable params: 20,513\n","Non-trainable params: 384\n","_________________________________________________________________\n"]}],"source":["pointnet_model = create_pointnet_model(conv_filters=[32, 64], conv_filter_factor=1, dense_hidden_units=64, dropout=.1)\n","pointnet_model.summary()"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1030037,"status":"ok","timestamp":1654093144737,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"},"user_tz":-120},"id":"-x3LUexOvEdG","outputId":"c4e2da79-113d-451d-f697-aeed3073f7b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['neighbors'] which did not match any model input. They will be ignored by the model.\n","  inputs = self._flatten_to_reference_inputs(inputs)\n"]},{"output_type":"stream","name":"stdout","text":["779/779 [==============================] - 227s 284ms/step - loss: 2.2940 - accuracy: 0.5382 - val_loss: 1.4285 - val_accuracy: 0.6277\n","Epoch 2/5\n","779/779 [==============================] - 192s 243ms/step - loss: 1.3795 - accuracy: 0.6364 - val_loss: 1.4325 - val_accuracy: 0.6538\n","Epoch 3/5\n","779/779 [==============================] - 207s 262ms/step - loss: 1.2343 - accuracy: 0.6574 - val_loss: 1.2623 - val_accuracy: 0.6745\n","Epoch 4/5\n","779/779 [==============================] - 182s 230ms/step - loss: 1.1434 - accuracy: 0.6813 - val_loss: 1.2255 - val_accuracy: 0.6835\n","Epoch 5/5\n","779/779 [==============================] - 190s 240ms/step - loss: 1.0846 - accuracy: 0.6898 - val_loss: 1.1954 - val_accuracy: 0.7005\n"]}],"source":["pointnet_model.compile(optimizer='adam',\n","                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n","                  metrics=['accuracy'])\n","\n","history = pointnet_model.fit(data_train, \n","                    validation_data=data_val, \n","                    epochs=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":263,"status":"aborted","timestamp":1654092108769,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"},"user_tz":-120},"id":"-CgM2bfnwylO"},"outputs":[],"source":["pointnet_model.evaluate(data_test)"]},{"cell_type":"markdown","source":["## FeastNet Example"],"metadata":{"id":"6SwdRzKnWOvZ"}},{"cell_type":"code","source":["def create_feastnet_model(features_filters=16, weight_matrices=8, out_channels=32, feast_layers=3, conv_out_filters=128, hidden_units=64):\n","    vertices = tf.keras.Input(name='vertices', shape=(max_num_vertices, info.features['trimesh']['vertices'].shape[-1]))\n","    neighbors = tf.keras.Input(name='neighbors', shape=(max_num_vertices, max_num_vertices), sparse=True)\n","\n","    conv = tf.keras.layers.Conv1D(features_filters, 1, activation=None)(vertices)\n","    for i in range(feast_layers):\n","        conv = FeatureSteeredConvolutionKerasLayer(num_weight_matrices=weight_matrices, num_output_channels=out_channels*2**i)([conv, neighbors])\n","        conv = tf.keras.layers.ReLU()(conv)\n","    graph_conv_output = tf.keras.layers.Conv1D(conv_out_filters, 1, activation='relu')(conv)\n","    graph_conv_output = tf.reduce_max(graph_conv_output, axis=1, keepdims=False)\n","    fc1 = tf.keras.layers.Dense(hidden_units, activation='relu')(graph_conv_output)\n","    fc2 = tf.keras.layers.Dense(hidden_units // 2, activation='relu')(fc1)\n","    outputs = tf.keras.layers.Dense(info.features['label'].num_classes, activation=None)(fc2)\n","    \n","    return tf.keras.Model(inputs=[vertices, neighbors], outputs=outputs)"],"metadata":{"id":"g_Y1AEAyWRzu","executionInfo":{"status":"aborted","timestamp":1654092108771,"user_tz":-120,"elapsed":265,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feastnet_model = create_feastnet_model(features_filters=16, weight_matrices=8, out_channels=16, feast_layers=2, conv_out_filters=64, hidden_units=64)\n","feastnet_model.summary()"],"metadata":{"id":"tO6-Em-Ae94E","executionInfo":{"status":"aborted","timestamp":1654092108771,"user_tz":-120,"elapsed":265,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feastnet_model.compile(optimizer='adam',\n","                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n","                  metrics=['accuracy'])\n","\n","history = feastnet_model.fit(data_train, \n","                    validation_data=data_val, \n","                    epochs=5)"],"metadata":{"id":"ihO5l3gCfATR","executionInfo":{"status":"aborted","timestamp":1654092108772,"user_tz":-120,"elapsed":266,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feastnet_model.evaluate(data_test)"],"metadata":{"id":"aVyusTpufYe1","executionInfo":{"status":"aborted","timestamp":1654092108772,"user_tz":-120,"elapsed":266,"user":{"displayName":"Michael Menzel","userId":"14743240657263179809"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"[EXAMPLE] Fun with TF Graphics and Trimesh.ipynb","provenance":[],"authorship_tag":"ABX9TyMoqu+22TZscEERxMK12h/V"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}