{"cells":[{"cell_type":"markdown","source":["# Vertex AI AutoML Object Detection - Show Batch Prediction Results (from JSONL files)\n","\n","Contributor: michaelmenzel@"],"metadata":{"id":"eXPg_uiK7Xus"},"id":"eXPg_uiK7Xus"},{"cell_type":"code","execution_count":null,"id":"da4de66f-ecae-4529-abf6-cf1842f3383d","metadata":{"id":"da4de66f-ecae-4529-abf6-cf1842f3383d"},"outputs":[],"source":["#@title Parameters { display-mode: \"form\" }\n","#@markdown Point to the bucket (and folder) with JSONL results from a batch prediction:\n","BUCKET = 'gs://license-plate-detection-us-central1/batch_predictions/prediction-license-plate-detection-us-central1_202161765327-2022-04-29T12:07:14.425828Z' #@param {type:\"string\"}\n","\n","#@markdown How many of the batch prediction results do we process?\n","MAX_RESULTS =  100#@param {type:\"integer\", min:1}\n","#@markdown How many of the batch prediction results should be skipped?\n","SKIP_RESULTS =  0#@param {type:\"integer\", min:1}\n","\n","#@markdown What is the min. confidence level to trust the model prediction (detecting a defect)?\n","THRESHOLD = 0.25 #@param {type:\"slider\", min:0, max:1, step:0.01}\n","#@markdown How many detected defects do we render on an image max?\n","TOP_K = 5 #@param {type:\"integer\", min:1}\n","\n","#@markdown Do we output images with defects during the processing (in the notebook)?\n","SHOW_EXAMPLES = True #@param {type:\"boolean\"}\n","\n","#@markdown [OPTIONAL] We (temporarily) store generated images in the following local folder:\n","OUTPUT_FOLDER = './test_output' #@param {type:\"string\"}\n","#@markdown [OPTIONAL] Font size of the annotation text.\n","FONTSIZE = 12 #@param {type:\"integer\", min:1}\n","\n","\n","import json\n","import os\n","from joblib import Parallel, delayed\n","from tqdm import tqdm\n","\n","import tensorflow as tf\n","import numpy as np\n","\n","from matplotlib import cm\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","plt.rcParams[\"figure.figsize\"] = (20,20)\n","\n","import googleapiclient.discovery\n","from google.oauth2 import service_account\n","\n","from google.colab import auth\n","from google.colab import files\n","\n","\n","!mkdir -p $OUTPUT_FOLDER\n","auth.authenticate_user()\n","\n","\n","def plot_prediction(image, bboxes, classes, confidences, show=False):\n","    with tf.io.gfile.GFile(image, 'rb') as ex_img:\n","        img_tensor = tf.io.decode_image(ex_img.read())\n","        max_width = img_tensor.shape[1]\n","        max_height = img_tensor.shape[0]\n","\n","        fig, ax = plt.subplots()\n","        ax.imshow(img_tensor)\n","        \n","        for bbox, cl, co in zip(bboxes, classes, confidences):\n","            x1 = max_width * np.min((bbox[0], bbox[1]))\n","            x2 = max_width * np.max((bbox[0], bbox[1]))\n","            y1 = max_height * np.min((bbox[2], bbox[3]))\n","            y2 = max_height * np.max((bbox[2], bbox[3]))\n","\n","            color = cm.get_cmap('RdYlGn')\n","            ax.add_patch(patches.Rectangle((x1, y1), x2-x1, y2-y1, \n","                                           linewidth=2, \n","                                           edgecolor=color(co), fill=False))\n","            ax.text(x1, y2, f'{cl}@{format(co, \".5f\")}', color=color(co), fontsize=FONTSIZE, verticalalignment='top')\n","            ax.set_axis_off()\n","            \n","            plt.savefig(os.path.join(OUTPUT_FOLDER, os.path.basename(image) + '.png'))\n","            \n","        plt.show() if show else plt.close(fig)\n","\n","\n","def process_result(result):\n","  threshold_filter = np.array(result['prediction']['confidences']) > THRESHOLD\n","  confidences = np.array(result['prediction']['confidences'])[threshold_filter]\n","  top_k = min(TOP_K, len(confidences))\n","  top_k_pos = np.argpartition(confidences, -top_k)[-top_k:]\n","  classes = np.array(result['prediction']['displayNames'])[top_k_pos]\n","  bboxes = np.array(result['prediction']['bboxes'])[top_k_pos]\n","    \n","  print('image:', result['instance']['content'], ', max confidences:', confidences, 'classes:', classes, 'bboxes:', bboxes)\n","  plot_prediction(result['instance']['content'], \n","                  np.array(result['prediction']['bboxes'])[top_k_pos],\n","                  np.array(result['prediction']['displayNames'])[top_k_pos],\n","                  np.array(result['prediction']['confidences'])[top_k_pos],\n","                  show=(len(confidences) & SHOW_EXAMPLES))\n","\n","\n","print('Loading batch prediction results...')\n","results = []\n","for file in tqdm(tf.io.gfile.glob(os.path.join(BUCKET, f'*.jsonl'))):\n","    with tf.io.gfile.GFile(file, mode=\"r\") as gf:\n","        for line in gf.readlines():\n","            results.append(json.loads(line))\n","\n","print('Annotating Images...')\n","Parallel(n_jobs=8, backend='multiprocessing')(delayed(process_result)(result) for result in tqdm(results[SKIP_RESULTS:MAX_RESULTS]))\n","    \n","print('Zipping and downloading annotated images...')\n","!zip -r -qq results.zip $OUTPUT_FOLDER \n","files.download('results.zip')"]}],"metadata":{"environment":{"kernel":"python3","name":"tf2-gpu.2-8.m91","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"colab":{"name":"[EXAMPLE] Vertex AI: AutoML Object Detection - Show Batch Prediction Results","provenance":[{"file_id":"1qYLAPdrYtc7qSR8vIvIT7419xVwx49Oj","timestamp":1651230841397}],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}